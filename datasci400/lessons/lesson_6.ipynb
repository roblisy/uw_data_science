{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned a lot about processing data in Python so far, but our emphasis has been to bring data into `pandas` as a `DataFrame` object, in other words: **tabular data**. But data is not always tabular and in this notebook we focus on some semi-structured data formats. Two things stand out the most about semi-structured data:\n",
    "\n",
    "1. There is usually no pre-set schema so we need to be extra careful when processing the data and be ready to catch different kinds of errors.\n",
    "1. The data is usually **hierarchical**, in other words information can be **nested** at various levels and we need to find the right way to **flatten** the data if we want to turn it into tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common types of semi-structured data is JSON. It has a very minimialist syntax, making it easy to explore. In Python, the natural object to represent JSON data is a Python dictionary, because of its flexibility and ability to nest information, and because it's a **key-value** store. So we can **load** a JSON file into a Python dictionary, or go the other around and **dump** a Python dictionary into a JSON file. JSON files also have support for **arrays**, which is the equivalent of a Python list. Here's an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, we create a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "dd = {\"a\": 1, \n",
    "      \"b\": [12, \"55\", [\"hello\", \"hi\"]], # we can have lists and nested lists\n",
    "      \"c\": {\"A\": \"bonjour\", \"B\": \"hola\"}, # we can have nested information\n",
    "     }\n",
    "\n",
    "print(type(dd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see how we can extract the information contained in it. Drill down into the dictionary to extract the following items:\n",
    "\n",
    "- the number 55\n",
    "- the string \"hi\"\n",
    "- the string \"hola\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'55'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd['b'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now dump the dictionary's content into a JSON file using the `json` library. Run the cell and open the file in your editor to examine it. Does the JSON file and the dictionary look almost identical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('delete_me.json', 'w') as outfile:\n",
    "    json.dump(dd, outfile) # you can set sort_keys = True if you wish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, note that we need to be careful not to equate the two: A dictionary can have many things in it, including for example a Python function. Return to the code above, and add a new element to it whose key is `\"d\"` and whose value is a Python function, like `print` or a function you wrote yourself. Then try to run the cell and report what error message you get, if any.\n",
    "\n",
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now go in the opposite direction. Since we just dumped the content of the dictionary into a JSON file, let's now read the file and load its content back into a dictionary. We use `load` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'a': 1, 'b': [12, '55', ['hello', 'hi']], 'c': {'A': 'bonjour', 'B': 'hola'}}\n"
     ]
    }
   ],
   "source": [
    "with open('delete_me.json', encoding = 'utf-8') as infile:\n",
    "    dd = json.load(infile)\n",
    "\n",
    "print(type(dd))\n",
    "print(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load directly from a string in Python, using the `loads` function (with an `s`), like the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'list'>\n",
      "{'drinks': ['coffee', 'tea', 'water']}\n"
     ]
    }
   ],
   "source": [
    "json_str = '{\"drinks\": [\"coffee\", \"tea\", \"water\"]}'\n",
    "dd = json.loads(json_str)\n",
    "print(type(dd)) # the JSON string becomes a Python dictionary\n",
    "print(type(dd[\"drinks\"])) # the JSON array becomes a Python list\n",
    "print(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once again we can go in the other direction by using `dumps` (with an `s`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"drinks\": [\"coffee\", \"tea\", \"water\"]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_str = json.dumps(dd)\n",
    "print(json_str)\n",
    "type(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go over one practical application for `loads` and `dumps`. One question that we may run into is what to do when the quantity of data is large and reading it all at once into our Python session is not an option. Is there a more light-weight approach to reading data gradually? The answer is yes, but we need to talk about reading raw text files in Python first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we have a large file, like the following. One important thing to notice about this file is that **each line is a JSON object, but the file as a whole is not**. It would be if we wrap it in square brackets and separate lines by commas, but we don't want to do that here, because we're not interested in reading the file all at once, but rather line by line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing delete_me.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile delete_me.txt\n",
    "{\"drinks\": [\"coffee\", \"tea\", \"water\"]}\n",
    "{\"drinks\": [\"coffee\", \"juice\", \"rum\", \"beer\"]}\n",
    "{\"drinks\": [\"vodka\", \"tapioca\", \"lulo\"]}\n",
    "{\"drinks\": [\"milk\", \"kambucha\", \"water\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Let's now read the above file. In our earlier example, we read files using the `with` statement, which has the advantage of closing files automatically for us, so we don't have to do our own cleanup. This time we're going to read our file without `with` to show the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"drinks\": [\"coffee\", \"tea\", \"water\"]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"delete_me.txt\", \"r\")\n",
    "print(file.readlines()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# show that readlines() can't be called twice consecutively\n",
    "print(file.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the line below, you'll see that we cannot load the file using `json.load` because as we said the file as a whole is not JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d0b55d156740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    " json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the content of the file above, we have two functions we can use. Let's first begin with `readlines` (with an `s`), which reads all the lines at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument should be integer or None, not '_io.TextIOWrapper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d5590fa18342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: argument should be integer or None, not '_io.TextIOWrapper'"
     ]
    }
   ],
   "source": [
    "file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of Python object did `readlines` return? You should be able to answer just from looking at it. Now run the above cell one more time. What is the output you see? Can you guess what happened? HINT: Go up and read the file one more time and then run the above cell.\n",
    "\n",
    "Write a code that reads the file and then write a loop that iterates over every element returned by `readlines` and prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"drinks\": [\"coffee\", \"tea\", \"water\"]}\n",
      "\n",
      "{\"drinks\": [\"coffee\", \"juice\", \"rum\", \"beer\"]}\n",
      "\n",
      "{\"drinks\": [\"vodka\", \"tapioca\", \"lulo\"]}\n",
      "\n",
      "{\"drinks\": [\"milk\", \"kambucha\", \"water\"]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"delete_me.txt\", \"r\")\n",
    "\n",
    "for i in file:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions like `readlines` are called **iterators** because they read some content broken up into pieces (how a text file is made up of lines) and return it as one big list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read the file again and this time we learn about another function: `readline` (without an `s`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"delete_me.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following line a few times, and report what you see every time you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"drinks\": [\"milk\", \"kambucha\", \"water\"]}\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will read one line at a time...\n",
    "# at the end of the file will just return a bunch of NULLs\n",
    "all_lines = file.readline()\n",
    "all_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions like `readline` are called **generators** because instead of reading the content all at once and returning one big list with everything, they return the content piecemeal (one line at a time in our case). Unlike iterators, generators don't need to load the entire content at once, and this means we can keep a low memory footprint when working with large objects in Python. And just like iterators, generators can be looped over.\n",
    "\n",
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read the file again and write a loop to read each line of the file and print it. Note that this is not as easy as working with iterators. One way to do it is use a `while True` statement and define a condition for breaking it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"drinks\": [\"coffee\", \"tea\", \"water\"]}\n",
      "\n",
      "{\"drinks\": [\"coffee\", \"juice\", \"rum\", \"beer\"]}\n",
      "\n",
      "{\"drinks\": [\"vodka\", \"tapioca\", \"lulo\"]}\n",
      "\n",
      "{\"drinks\": [\"milk\", \"kambucha\", \"water\"]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"delete_me.txt\", \"r\")\n",
    "\n",
    "while True:\n",
    "    line = file.readline()\n",
    "    if line != \"\": # we assume that if line == \"\" we've reached EOF\n",
    "        print(line)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to put it all together. We write a loop that does the following at each iteration:\n",
    "\n",
    "- read the next line of the input file\n",
    "- use `json.loads` to load it as a dictionary\n",
    "- calculate the number of drinks and add it to the dictionary using `size` as key\n",
    "- dump the content to an output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = open(\"delete_me.txt\", \"r\")\n",
    "out_file = open(\"delete_me_out.txt\", \"w\") # change w to a if you want to append\n",
    "\n",
    "while True:\n",
    "    line = in_file.readline()\n",
    "    if line != \"\": # we assume that if line == \"\" we've reached EOF\n",
    "        line_dict = json.loads(line)\n",
    "        line_dict['size'] = len(line_dict['drinks'])\n",
    "        json.dump(line_dict, out_file) # dump content into file\n",
    "        out_file.write('\\n') # add a line break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "out_file.close() # don't forget to close the file when you're done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to open the file and check the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common data structure with a very minimalistic syntax and similarities with JSON is YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'EN': 'he dropped the cup on the floor',\n",
      "  'SP': ['se le cayÃ³ la taza al suelo', 'dejo caer la taza al suelo'],\n",
      "  'tags': {'diff': 4, 'en': None, 'sp': None}},\n",
      " {'EN': 'in bad times you really get to know your friends',\n",
      "  'SP': 'en las malas se conocen a los amigos',\n",
      "  'tags': {'diff': 2, 'en': None, 'sp': 'proverb'}},\n",
      " {'EN': 'to each their own',\n",
      "  'SP': 'cada loco con su tema',\n",
      "  'tags': {'diff': 2, 'en': 'idiom', 'sp': 'idiom'}},\n",
      " {'EN': \"I'd like to return the favor for their generosity\",\n",
      "  'SP': 'quisiera corresponder a su generosidad',\n",
      "  'tags': {'diff': None, 'en': None, 'sp': None}},\n",
      " {'EN': 'he loves her but she responds with contempt and rudeness',\n",
      "  'SP': 'la ama y ella le corresponde con desprecio y groserÃ\\xada',\n",
      "  'tags': {'diff': None, 'en': None, 'sp': None}},\n",
      " {'EN': 'a story of unrequited love',\n",
      "  'SP': 'la historia de un amor no correspondido',\n",
      "  'tags': {'diff': None, 'en': None, 'sp': None}},\n",
      " {'EN': \"that's totally out of keeping with her character\",\n",
      "  'SP': 'eso no [se] corresponde para nada con su manera de ser',\n",
      "  'tags': {'diff': None, 'en': None, 'sp': None}},\n",
      " {'EN': 'bad weather forced us to postpone our departure',\n",
      "  'SP': 'el mal tiempo nos obligÃ³ a retrasar la partida',\n",
      "  'tags': {'diff': None, 'en': None, 'sp': None}},\n",
      " {'EN': 'I made him apologize to his grandmother',\n",
      "  'SP': 'lo obliguÃ© a pedirle perdÃ³n a la abuela',\n",
      "  'tags': {'diff': None, 'en': None, 'sp': None}},\n",
      " {'EN': 'make them pick up their toys',\n",
      "  'SP': 'oblÃ\\xadgalos a que recojan los juguetes',\n",
      "  'tags': {'diff': None, 'en': None, 'sp': None}}]\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "with open(\"data/spen.yaml\", encoding = 'utf-8') as file:\n",
    "    en_sp = yaml.load(file, Loader = yaml.FullLoader)\n",
    "\n",
    "pprint(en_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One advantage of YAML is its support for references, called **anchors** by YAML, but that's a topic we won't get into. Suffice it to say that for this reason YAML is a popular format for configuration files, like the **conda** environment we're using for the course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-54-fe76f0979a70>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-54-fe76f0979a70>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    channels:\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# %load config/environment.yml\n",
    "name: uwdatasci400\n",
    "\n",
    "channels:\n",
    "  - defaults\n",
    "  - conda-forge\n",
    "\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - scikit-learn=0.20.3\n",
    "  - seaborn=0.10.0\n",
    "  - category_encoders=2.0.0\n",
    "  - joblib=0.14.1\n",
    "  - jupyter=1.0.0\n",
    "  - ipykernel=5.1.4\n",
    "  - mlxtend=0.17.2\n",
    "  - graphviz=2.38\n",
    "  - pip=19.0.1\n",
    "  - requests=2.23.0\n",
    "  - pyyaml=5.3.1\n",
    "\n",
    "  - pip:\n",
    "    - pylint\n",
    "    - pandas==1.0.1\n",
    "    - bs4==4.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Read the file `config/environment.yml` into Python and write a loop to print all the packages defined in our conda environment, including the `pip` packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python=3.6',\n",
      " 'scikit-learn=0.20.3',\n",
      " 'seaborn=0.10.0',\n",
      " 'category_encoders=2.0.0',\n",
      " 'joblib=0.14.1',\n",
      " 'jupyter=1.0.0',\n",
      " 'ipykernel=5.1.4',\n",
      " 'mlxtend=0.17.2',\n",
      " 'graphviz=2.38',\n",
      " 'pip=19.0.1',\n",
      " 'requests=2.23.0',\n",
      " 'pyyaml=5.3.1',\n",
      " {'pip': ['pylint', 'pandas==1.0.1', 'bs4==4.9.0']}]\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open('config/environment.yml') as config_yml:\n",
    "    # safe_load() to avoid arbitrary object execution\n",
    "    config_data = yaml.safe_load(config_yml)\n",
    "    pprint(config_data[\"dependencies\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON and YAML are relatively new data structures, and quickly gaining in popularity. Prior to that, XML was very common, and it's sytnax is definitely more verbose. Here is an example of an XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<CATALOG>\n",
      "  <CD>\n",
      "    <TITLE>Empire Burlesque</TITLE>\n",
      "    <ARTIST>Bob Dylan</ARTIST>\n",
      "    <COUNTRY>USA</COUNTRY>\n",
      "    <COMPANY>Columbia</COMPANY>\n",
      "    <PRICE>10.90</PRICE>\n",
      "    <YEAR>1985</YEAR>\n",
      "  </CD>\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.w3schools.com/xml/cd_catalog.xml'\n",
    "document = requests.get(url)\n",
    "\n",
    "print(document.text[:249]) # show a small chunk of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in XML as we can see is also hierarchical, and each piece of data is surrounded in **tags**, which are identified by `<TAG>` and `</TAG>` where `TAG` in our case is be `CD`, `TITLE`, etc. The tags in XML are similar to the keys in a JSON file. So we can see the above data is a CD catalogue, which contains a title, artist name, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read this type of data we use the `BeautifulSoup` function in the `bs4` package, but keep in mind that there are alternative packages we could have used, such as `lxml`, which offers support for **XPath**, which is a query language for XML documents. We do not cover XPath here, but encourage you to look into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(document.content,\"lxml-xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BeautifulSoup` does not support searching an XML file using XPath, but it does have its own functionality for searching XML. We can use `find` to find the **first** occurence of a tag and use `find_all` to find all the occurences of a tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TITLE>Empire Burlesque</TITLE>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(\"TITLE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish to extract the text itself without the tag, we can use the `text` attribute of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empire Burlesque\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(\"TITLE\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use `find_all` to find all the occurences of the `TITLE` tag, and write a loop to extract and print the text attribute of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empire Burlesque\n",
      "Hide your heart\n",
      "Greatest Hits\n",
      "Still got the blues\n",
      "Eros\n",
      "One night only\n",
      "Sylvias Mother\n",
      "Maggie May\n",
      "Romanza\n",
      "When a man loves a woman\n",
      "Black angel\n",
      "1999 Grammy Nominees\n",
      "For the good times\n",
      "Big Willie style\n",
      "Tupelo Honey\n",
      "Soulsville\n",
      "The very best of\n",
      "Stop\n",
      "Bridge of Spies\n",
      "Private Dancer\n",
      "Midt om natten\n",
      "Pavarotti Gala Concert\n",
      "The dock of the bay\n",
      "Picture book\n",
      "Red\n",
      "Unchain my heart\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(document.content,\"lxml-xml\")\n",
    "\n",
    "for i in soup.find_all(\"TITLE\"):\n",
    "    print (i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an XML file looks familiar it's because it's format is almost the same as HTML, which what web pages use to store their content. In fact, HTML and XML are practically the same thing, with the difference that **with HTML the tags are pre-defined** whereas XML tags are whatever we choose. This makes XML a repository for any data, whereas HTML is a repository for a web page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Web scraping** refers to writing programs that extract information from websites. It shouldn't surprise you that information found in websites is very disorganized and disparate. As such, there's a lot of work that go into cleaning it once we read it. We introduce you to some libraries that make this easier, but at the end of the day a lot of this functionality depends on the website we're trying to scrape, so it involves a lot of trial and error. But the tooling that we learned for XML can in most cases be directly applied to HTML as we're about to see.\n",
    "\n",
    "Let's send an HTTP request to scrape wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date': 'Fri, 15 May 2020 03:42:07 GMT', 'Server': 'Apache', 'Vary': 'Cookie,User-Agent,Accept-Encoding', 'Set-Cookie': 'MOIN_SESSION_443_ROOT_moin=a0e6ba2c1b28031cbc4b01841bf9084f491419ab; Expires=Fri, 15-May-2020 04:42:00 GMT; Max-Age=3600; Secure; Path=/', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains', 'Content-Encoding': 'gzip', 'Content-Length': '40604', 'Keep-Alive': 'timeout=5, max=100', 'Connection': 'Keep-Alive', 'Content-Type': 'text/html; charset=utf-8'}\n",
      "b'<!DOCTYPE HTML PUBLIC \"-//W3C/'\n"
     ]
    }
   ],
   "source": [
    "url = \"https://wiki.python.org/moin/IntroductoryBooks\" \n",
    "response = requests.get(url)\n",
    "print(response.headers)\n",
    "\n",
    "content = response.content\n",
    "print(content[:30]) # print a small section of the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the above information is just in raw text format. To clean it up, we can use the `bs4` library. Since websites requests are sent back as HTML files, the job of `BeautifulSoup` function is to **parse** the HTML for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(content, \"html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `prettify` function to print the HTML in a more readable format where the hierarchy of nested **HTML tags** can be seen. Some tags contain **elements**. For example `<input id=\"fullsearch\">...</input>` is the `input` tag and `id` is one of its elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n",
      "<html>\n",
      " <head>\n",
      "  <meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <meta content=\"text/html;charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "  <meta content=\"index,nofollow\" name=\"robots\"/>\n",
      "  <title>\n",
      "   IntroductoryBooks - Python Wiki\n",
      "  </title>\n",
      "  <script src=\"/wiki/common/js/common.js\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script ty\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The soup object can help us extract specific tags out. Because tags for an HTML file are pre-defined (unlike XML), there are some shortcuts for searching HTML. For example, if we want the `title` tag, we can just use the `title` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>IntroductoryBooks - Python Wiki</title>\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we just want the content of the `title` tag, without the tag wrapper, we can use the `text` attribute just like we did with XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IntroductoryBooks - Python Wiki\n"
     ]
    }
   ],
   "source": [
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many tags show up not once but many times in the HTML document, so we can use `soup.find_all` to search tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/moin/FrontPage\"></a>\n",
      "<a href=\"http://www.python.org\"><img alt=\"Python\" src=\"/wiki/europython/img/python-logo.gif\"/></a>\n",
      "<a name=\"logo\"></a>\n",
      "<a href=\"/moin/IntroductoryBooks\">IntroductoryBooks</a>\n",
      "<a href=\"/moin/IntroductoryBooks\">IntroductoryBooks</a>\n",
      "<a href=\"/moin/FrontPage\">FrontPage</a>\n",
      "<a href=\"/moin/RecentChanges\">RecentChanges</a>\n",
      "<a href=\"/moin/FindPage\">FindPage</a>\n",
      "<a href=\"/moin/HelpContents\">HelpContents</a>\n",
      "<a href=\"/moin/IntroductoryBooks\">IntroductoryBooks</a>\n",
      "<a class=\"nbcomment\" href=\"#\" onclick=\"toggleComments();return false;\">Comments</a>\n",
      "<a class=\"nbinfo\" href=\"/moin/IntroductoryBooks?action=info\" rel=\"nofollow\">Info</a>\n",
      "<a class=\"nbattachments\" href=\"/moin/IntroductoryBooks?action=AttachFile\" rel=\"nofollow\">Attachments</a>\n",
      "<a href=\"/moin/IntroductoryBooks?action=login\" id=\"login\" rel=\"nofollow\">Login</a>\n",
      "<a href=\"/moin/PythonBooks\">PythonBooks</a>\n",
      "<a href=\"/moin/ReferenceBooks\">ReferenceBooks</a>\n",
      "<a class=\"https\" href=\"https://www.amazon.com/Python-3-8-Nat-Dunn/dp/1951959027\">Actionable Python 3.8</a>\n",
      "<a class=\"https\" href=\"https://www.learningiot.net/\">Learning IoT Page</a>\n",
      "<a class=\"https\" href=\"https://www.barnesandnoble.com/w/learning-iot-with-python-and-raspberry-pi-ei-horvath/1133345171?ean=9780578549361\">Learning IoT with Python and Raspberry Pi</a>\n",
      "<a class=\"https\" href=\"https://www.learningiot.net/\">Learning IoT Page</a>\n"
     ]
    }
   ],
   "source": [
    "all_a = soup.find_all(\"a\") # the a tag contains an element called href for hyperlinks\n",
    "\n",
    "for x in all_a[:20]: # print the top 20\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Let's print of the lines form above here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"https\" href=\"https://www.amazon.com/gp/product/B07ZY7XMX8\">Python One-Liners</a>\n"
     ]
    }
   ],
   "source": [
    "x = all_a[20]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing that the hrefs resolve in markdown... \n",
    "<a class=\"https\" href=\"https://www.amazon.com/gp/product/B07ZY7XMX8\">Python One-Liners</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the output of the above cell and paste it into a new Markdown cell in your notebook. What do you see when you render the cell?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also extract just the URL by using the `get` method and passing it the name of the element, `href` in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python One-Liners\n",
      "https://www.amazon.com/gp/product/B07ZY7XMX8\n"
     ]
    }
   ],
   "source": [
    "print(x.text) # this is the title of the URL (what you see when you click on it)\n",
    "print(x.get(\"href\")) # this is the URL (the link you go to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `find_all` we can also narrow our search by finding for example all `a` tags that have an element called `https`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"https\" href=\"https://www.amazon.com/Python-3-8-Nat-Dunn/dp/1951959027\">Actionable Python 3.8</a>\n",
      "<a class=\"https\" href=\"https://www.learningiot.net/\">Learning IoT Page</a>\n",
      "<a class=\"https\" href=\"https://www.barnesandnoble.com/w/learning-iot-with-python-and-raspberry-pi-ei-horvath/1133345171?ean=9780578549361\">Learning IoT with Python and Raspberry Pi</a>\n",
      "<a class=\"https\" href=\"https://www.learningiot.net/\">Learning IoT Page</a>\n",
      "<a class=\"https\" href=\"https://www.amazon.com/gp/product/B07ZY7XMX8\">Python One-Liners</a>\n",
      "<a class=\"https\" href=\"https://pythononeliners.com/\">Book page (free material)</a>\n",
      "<a class=\"https\" href=\"https://nostarch.com/pythononeliners\">Publisher's page</a>\n",
      "<a class=\"https\" href=\"https://www.packtpub.com/application-development/learn-programming-python-cody-jackson\">Learn Programming in Python with Cody Jackson</a>\n",
      "<a class=\"https\" href=\"https://www.packtpub.com/application-development/learn-programming-python-cody-jackson\">Publisher's page</a>\n",
      "<a class=\"https\" href=\"https://www.packtpub.com/application-development/python-3-object-oriented-programming-third-edition\">Python 3 Object-Oriented Programming - Third Edition</a>\n",
      "<a class=\"https\" href=\"https://www.packtpub.com/application-development/python-3-object-oriented-programming-third-edition\">Publisher's page</a>\n",
      "<a class=\"https\" href=\"https://www.packtpub.com/application-development/python-apprentice\">The Python Apprentice</a>\n",
      "<a class=\"https\" href=\"https://www.packtpub.com/application-development/python-apprentice\">Publisher's page</a>\n",
      "<a class=\"https\" href=\"https://www.packtpub.com/application-development/learn-python-7-days\">Learn Python in 7 Days</a>\n",
      "<a class=\"https\" href=\"https://www.packtpub.com/application-development/learn-python-7-days\">Publisher's page</a>\n",
      "<a class=\"https\" href=\"https://www.packtpub.com/packt/free-ebook/what-you-need-know-about-machine-learning2\">What You Need to Know about Machine Learning</a>\n",
      "<a class=\"https\" href=\"https://www.packtpub.com/packt/free-ebook/what-you-need-know-about-machine-learning2\">Publisher's Page</a>\n",
      "<a class=\"https\" href=\"https://www.packtpub.com/packt/free-ebook/what-you-need-know-about-python2\">What You Need to Know about Python</a>\n",
      "<a class=\"https\" href=\"https://www.packtpub.com/packt/free-ebook/what-you-need-know-about-python2\">Publisher's Page</a>\n",
      "<a class=\"https\" href=\"https://www.manning.com/books/get-programming\">Learn Python</a>\n"
     ]
    }
   ],
   "source": [
    "all_a_https = soup.find_all(\"a\", \"https\")   \n",
    "\n",
    "for x in all_a_https[:20]: # print the top 20\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Create a Python dictionary by looping through the elements of `all_a_https` and making the URL title the key and the URL itself the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Actionable Python 3.8': 'https://www.amazon.com/Python-3-8-Nat-Dunn/dp/1951959027', 'Learning IoT Page': 'https://www.learningiot.net/', 'Learning IoT with Python and Raspberry Pi': 'https://www.barnesandnoble.com/w/learning-iot-with-python-and-raspberry-pi-ei-horvath/1133345171?ean=9780578549361', 'Python One-Liners': 'https://www.amazon.com/gp/product/B07ZY7XMX8', 'Book page (free material)': 'https://pythononeliners.com/', \"Publisher's page\": 'https://www.packtpub.com/application-development/learn-python-7-days', 'Learn Programming in Python with Cody Jackson': 'https://www.packtpub.com/application-development/learn-programming-python-cody-jackson', 'Python 3 Object-Oriented Programming - Third Edition': 'https://www.packtpub.com/application-development/python-3-object-oriented-programming-third-edition', 'The Python Apprentice': 'https://www.packtpub.com/application-development/python-apprentice', 'Learn Python in 7 Days': 'https://www.packtpub.com/application-development/learn-python-7-days', 'What You Need to Know about Machine Learning': 'https://www.packtpub.com/packt/free-ebook/what-you-need-know-about-machine-learning2', \"Publisher's Page\": 'https://www.packtpub.com/packt/free-ebook/what-you-need-know-about-python2', 'What You Need to Know about Python': 'https://www.packtpub.com/packt/free-ebook/what-you-need-know-about-python2', 'Learn Python': 'https://www.manning.com/books/get-programming'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Single element: https://www.learningiot.net/\n"
     ]
    }
   ],
   "source": [
    "all_a_https = soup.find_all(\"a\", \"https\")   \n",
    "\n",
    "# make an empty dictionary.\n",
    "soup_dict = {}\n",
    "# append entries in the dictionary in a loop\n",
    "for x in all_a_https[:20]: # print the top 20\n",
    "    soup_dict.update({x.text : x.get(\"href\")})\n",
    "    \n",
    "print(soup_dict)\n",
    "print('\\n\\n\\n')\n",
    "print('Single element: ' + str(soup_dict['Learning IoT Page']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we saw some simple examples of dealing with unstructured data. Of course this there is so much more to say about the subject. So if this is something that as a data-scientist you see yourself doing often, we invite you to learn more. You can simply search the term \"web-scraping with Python\" to find many books and other resources that cover this topic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
