{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithms for Logistic Regression Feature Selection\n",
    "\n",
    "<hr style=\"border:5px solid green\"> </hr>\n",
    "\n",
    "### Background\n",
    "\n",
    "Microarray data is data generated from measuring the \"expression of a gene (s)\". Generally, the idea is to predict an attribute of the cell sample (cancerous cell, antibiotic resistance, etc), and see which levels of what gene expression are correlated or can be used to predict the attribute.\n",
    "\n",
    "It is easy to measure many gene expressions at once, but sometimes very hard to get many different tissue/cell samples. This results in a very large feature set and a much smaller observation count. ( column count >>> row count )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will use a UCI public microarray dataset here for a type of cancerous cell prediction.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq\n",
    "\n",
    "\n",
    "Please navigate to `Data Folder` and download the zip/tar file. When that is downloaded, unzip the file and it should contain two files `data.csv` and `labels.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('TCGA-PANCAN-HiSeq-801x20531')\n",
    "data_file = os.path.join(data_dir, 'data.csv')\n",
    "label_file = os.path.join(data_dir, 'labels.csv')\n",
    "\n",
    "ma_df = pd.read_csv(data_file)\n",
    "targets = pd.read_csv(label_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid red\"> </hr>\n",
    "\n",
    "> Note: this is a CONTRIVED example. We use it for illustration on using a genetic algorithm for feature selection. We can imagine using this for hyperparameter selection or even model selection as needed.  However, know that with each individual we test, we are performing a statistical hypothesis test.\n",
    "\n",
    "> It is recommended to use NON target dependent methods for feature selection first, like PCA. Or use limited iteration methods like forward/backwards selection at least.  This example will scour nearly every possible feature combination for one that performs well.\n",
    "\n",
    "> At the very least, we can incorporate lots of regularization and penalize it.\n",
    "\n",
    "<hr style=\"border:5px solid red\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too much for logistic regression.\n",
    "# We filter for illustrative purposes.\n",
    "ma_df = ma_df.iloc[:, 0:1001]\n",
    "\n",
    "# Add target column back into dataset\n",
    "# We also only want to predict the 'BRCA' type of cancer to keep this to a single class prediction problem:\n",
    "#.   our target will be: 'BRCA' and 'not BRCA'\n",
    "ma_df['target'] = targets['Class'] == 'BRCA'\n",
    "ma_df['target'] = ma_df['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Validation, Test, and Train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test, valid = train_test_split(ma_df, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train  = train_test_split(ma_df, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('valid_df shape: {}'.format(valid.shape))\n",
    "print('test_df shape: {}'.format(train.shape))\n",
    "print('train_df shape: {}'.format(test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'target'\n",
    "feature_cols = [x for x in ma_df.columns if 'gene_' in x]\n",
    "print('Number of genes (features): {:,}'.format(len(feature_cols)))\n",
    "\n",
    "# GA Params\n",
    "pop_size = 100\n",
    "individual_length = len(feature_cols)\n",
    "p_mutation = 50/n_genes\n",
    "selection_strength = 0.10\n",
    "generations = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Population Functions\n",
    "\n",
    "<hr style=\"border:3px solid green\"> </hr>\n",
    "\n",
    "1. Population Initialization\n",
    "\n",
    "2. Fitness Evaluation\n",
    "\n",
    "3. Selection\n",
    "\n",
    "4. Recombination\n",
    "\n",
    "5. Mutation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population initialization:\n",
    "\n",
    "def initialize_pop(pop_size, individual_length):\n",
    "    \"\"\"\n",
    "    Description: Return a randomly initialized population.\n",
    "    Args:\n",
    "     -pop_size\n",
    "     -individual_length\n",
    "    Return: numpy array. Array of N-popuation vectors, each of length 'individual_length', N=pop_size.\n",
    "    \"\"\"\n",
    "    population = np.random.choice([1, 0], size=(pop_size, individual_length))\n",
    "\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = initialize_pop(pop_size, individual_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(population.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population[0:3, 0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness Evaluation\n",
    "\n",
    "def get_individual_fitness(individual, df, features):\n",
    "    \"\"\"\n",
    "    Description: Evaluate an individual solution fitness.\n",
    "    Args:\n",
    "     - individual: np.array, size (1 x individual_length).\n",
    "     - x_data: np.array.\n",
    "     - features: list. list of feature names.\n",
    "    Return: fitness.\n",
    "    \"\"\"\n",
    "    # Define classifier\n",
    "    clf = linear_model.LogisticRegression(penalty='l1', solver='liblinear', tol=1e-6, max_iter=int(1e6), C=0.01)\n",
    "    \n",
    "    # Get features from individual\n",
    "    gene_cols = [x for x, indicator in zip(features, individual) if indicator==1]\n",
    "    \n",
    "    # Fit on x_dataset\n",
    "    clf.fit(df.loc[:, gene_cols], df[target_col])\n",
    "    \n",
    "    # Get f1-score\n",
    "    pred_outcomes = clf.predict(df.loc[:, gene_cols])\n",
    "    f1_fitness = f1_score(df[target_col].values, pred_outcomes)\n",
    "    \n",
    "    return f1_fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection Function\n",
    "\n",
    "def selection(population, pop_fitness, selection_strength):\n",
    "    \"\"\"\n",
    "    Description: Perform Selection on Population- return a subpopulation of the highest fit population.\n",
    "    Args:\n",
    "     - population: np.array, size (pop_size x individual_length).\n",
    "     - pop_fitness: np.array. Array of fitness values corresponding to each individual in prior population.\n",
    "     - selection_strength. Float. 0<x<1, % of top individuals to keep. Lower is more restrictive.\n",
    "    Return: np.array. size ( floor(selection_strength * population) x individual_length )\n",
    "    \"\"\"\n",
    "    # Figure out how many to save:\n",
    "    num_to_save = int(np.floor(selection_strength * population.shape[0]))\n",
    "    \n",
    "    # Get indices of N top fit individuals (smallest MSE is best)\n",
    "    # individuals_to_save = pop_fitness.argsort()[:num_to_save]\n",
    "    \n",
    "    # For maximizing fitness:\n",
    "    individuals_to_save = pop_fitness.argsort()[-num_to_save:][::-1]\n",
    "    \n",
    "    # Save top fit parent population\n",
    "    parents = population[individuals_to_save, :]\n",
    "    \n",
    "    return parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recombination Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recombination Function\n",
    "\n",
    "def recombination(parent_pop, pop_size):\n",
    "    \"\"\"\n",
    "    Description: Recombine parents to create new children solutions.\n",
    "    Args:\n",
    "     - parent_pop: np.array, size (parent_size x individual_length).\n",
    "     - pop_size: Integer. Total population to make up\n",
    "    Return: np.array. size ( pop_size x individual_length )\n",
    "    \"\"\"\n",
    "    # Figure out how many children to create\n",
    "    num_children = pop_size - parent_pop.shape[0]\n",
    "    \n",
    "    # Initialize Children\n",
    "    children = np.zeros(shape=(num_children, parent_pop.shape[1]))\n",
    "    \n",
    "    # Loop and create each child\n",
    "    for c in range(num_children):\n",
    "        # Randomly get two parents\n",
    "        parents = parent_pop[np.random.randint(0,parent_pop.shape[0],2)]\n",
    "        \n",
    "        # Select a random crossover location\n",
    "        crossover_pt = np.random.randint(1, high=(parent_pop.shape[1] - 1))\n",
    "        \n",
    "        # Create child\n",
    "        children[c, :crossover_pt] = parents[0, :crossover_pt]\n",
    "        children[c, crossover_pt:] = parents[1, crossover_pt:]\n",
    "        \n",
    "    return children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutation Function\n",
    "\n",
    "def mutation(individual, p_mutation):\n",
    "    \"\"\"\n",
    "    Description: Mutate Child Population.\n",
    "    Args:\n",
    "     - individual: np.array, size (1 x individual_length).\n",
    "     - p_mutation: Float. 0<x<1. Probability of mutation of each sub-parameter of a single individual.\n",
    "    Return: np.array. size ( 1 x individual_length )\n",
    "    \"\"\"\n",
    "    # Generate a probability vector, same size as individual using the uniform distribution.\n",
    "    prob_vector = np.random.uniform(low=0.0, high=1.0, size=individual_length)\n",
    "    \n",
    "    # Find where to mutate individual\n",
    "    ix_to_mutate = np.argwhere(prob_vector < p_mutation)\n",
    "    \n",
    "    # Mutate individual\n",
    "    if ix_to_mutate.size > 0:\n",
    "        new_vals = np.random.choice([0, 1], size=ix_to_mutate.shape)\n",
    "        individual[ix_to_mutate] = new_vals\n",
    "        \n",
    "    return individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fitness_sequence = []\n",
    "best_fitness = 0.0\n",
    "\n",
    "for g in range(generations):\n",
    "    print('Starting generation {:,} out of {:,}: {}'.format(g + 1, generations, best_fitness))\n",
    "    \n",
    "    # Get fitness of population\n",
    "    pop_fitness = np.apply_along_axis(get_individual_fitness, 1, population, ma_df, feature_cols)\n",
    "    \n",
    "    # Save best fitness\n",
    "    best_fitness = np.max(pop_fitness)\n",
    "    best_ix = np.argmax(pop_fitness)\n",
    "    best_fitness_sequence.append(best_fitness)\n",
    "    \n",
    "    # Get parents\n",
    "    parents = selection(population, pop_fitness, selection_strength)\n",
    "    \n",
    "    # Create children from parents\n",
    "    children = recombination(parents, pop_size)\n",
    "    \n",
    "    # Mutate children\n",
    "    children = np.apply_along_axis(mutation, 1, children, p_mutation)\n",
    "    \n",
    "    # Combine parents and children\n",
    "    population = np.concatenate((parents, children), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best F1 score: {}'.format(best_fitness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot F1 score vs Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_seq = np.arange(len(best_fitness_sequence))\n",
    "\n",
    "plt.plot(g_seq, np.array(best_fitness_sequence))\n",
    "plt.xlabel('Num of Generations')\n",
    "plt.ylabel('F1 Score (Fitness)')\n",
    "plt.title('F1 vs Generations')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
