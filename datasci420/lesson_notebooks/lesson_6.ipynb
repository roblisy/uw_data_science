{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:8px solid red\"> </hr>\n",
    "\n",
    "# Start Recording\n",
    "\n",
    "# Ensemble models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we learn about ensemble modeling, which is a technique for training multiple ML algorithms (referred to as `base learners`) and combining their learning into one. Two very common ways of doing this are **bagging** and **boosting**.\n",
    "\n",
    "## Reading and processing data\n",
    "\n",
    "Let begin by reading our data. In this case, our data is already split into training and testing. How convenient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <=50K    24720\n",
      " >50K      7841\n",
      "Name: Target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education_Num</th>\n",
       "      <th>Martial_Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital_Gain</th>\n",
       "      <th>Capital_Loss</th>\n",
       "      <th>Hours_per_week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age          Workclass  fnlwgt   Education  Education_Num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        Martial_Status          Occupation    Relationship    Race      Sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   Capital_Gain  Capital_Loss  Hours_per_week         Country  Target  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"adult_train.csv\", sep = \",\", header = 0)\n",
    "df_test = pd.read_csv(\"adult_test.csv\", sep = \",\", skiprows = 2, names = df_train.columns)\n",
    "print(df_train['Target'].value_counts(sort=True))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our column types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                int64\n",
       "Workclass         object\n",
       "fnlwgt             int64\n",
       "Education         object\n",
       "Education_Num      int64\n",
       "Martial_Status    object\n",
       "Occupation        object\n",
       "Relationship      object\n",
       "Race              object\n",
       "Sex               object\n",
       "Capital_Gain       int64\n",
       "Capital_Loss       int64\n",
       "Hours_per_week     int64\n",
       "Country           object\n",
       "Target            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Details:\n",
    "https://archive.ics.uci.edu/ml/datasets/adult\n",
    "\n",
    "Let's create a list of our categorical columns. Here keep every column whose data types is `object`, but we may need to narrow the list down even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Workclass',\n",
       " 'Education',\n",
       " 'Martial_Status',\n",
       " 'Occupation',\n",
       " 'Relationship',\n",
       " 'Race',\n",
       " 'Sex',\n",
       " 'Country',\n",
       " 'Target']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars = df_train.select_dtypes('object').columns.to_list()\n",
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Workclass',\n",
       " 'Education',\n",
       " 'Martial_Status',\n",
       " 'Occupation',\n",
       " 'Relationship',\n",
       " 'Race',\n",
       " 'Sex',\n",
       " 'Country']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars.pop() # removes `target=income` from cat_vars\n",
    "cat_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these columns look like they would be good candidates type `category`, but we covered that in a previous notebook and no need to return to that. We will take them as-is.\n",
    "\n",
    "Let's drop any rows with missing data from the training and test sets. This is a very conservative approach and if we don't have a lot of data to begin with we may want to try a different approach such as imputing the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (30162, 15)\n",
      "Test shape: (15060, 15)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.dropna(axis = 0)\n",
    "df_test = df_test.dropna(axis = 0)\n",
    "\n",
    "print('Train shape: {}'.format(df_train.shape))\n",
    "print('Test shape: {}'.format(df_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the data into features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns = 'Target')\n",
    "Y_train = df_train['Target']\n",
    "\n",
    "X_test = df_test.drop(columns = 'Target')\n",
    "Y_test = df_test['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of data pre-processing, we need to one-hot-encode the categorical features. We already learned how to use `OneHotEncoder` in `sklearn.preprocessing`, but we will use another `OneHotEncoder` this time in the `category_encoders` library. It's important to know that `sklearn` is not the only library for ML in Python, so this will give us a change to try a new one. You should not be surprised to find out that the two have a lot in common, but also some slight additions that make things easier for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying it to the data, let's create a very small train and test data with two rows and two columns and intentiall modify them slightly, just to learn how `OneHotEncoder` works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Race    Sex\n",
       "2   White   Male\n",
       "3   Black    NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_small_train = X_train.loc[2:3, [\"Race\", \"Sex\"]]\n",
    "X_small_train.iloc[1, 1] = np.nan # introduce a nan to see what happens\n",
    "X_small_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Race      Sex\n",
       "4   Black   Female\n",
       "5   White   Female"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small_test = X_train.loc[4:5, [\"Race\", \"Sex\"]]\n",
    "X_small_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `OneHotEncoder` class has two very important arguments called `handle_missing` and `handle_unknown` ethier of which can be set to `\"error\"`, `\"return_nan\"`, `\"value\"` or `\"indicator\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "handle = 'value' # options are: 'error', 'return_nan', 'value', and 'indicator'\n",
    "onehoter =  ce.OneHotEncoder(return_df = True, \n",
    "                             cols = [\"Race\", \"Sex\"], \n",
    "                             drop_invariant = False,####\n",
    "                             use_cat_names = True, \n",
    "                             handle_missing = handle, \n",
    "                             handle_unknown = handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid red\"> </hr>\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Let's examing the following settings and describe what happens when you run `onehoter.fit` on `X_small_train` and then run `onehoter.transform` on `X_small_train` and `X_small_test`.\n",
    "\n",
    "- Set `handle = \"indicator\"` and `drop_invariant = False`.\n",
    "- Set `handle = \"error\"`.\n",
    "- Set `handle = \"value\"` and `drop_invariant = True`.\n",
    "- Set `handle = \"value\"` and `drop_invariant = False`.\n",
    "- Set `handle = \"return_nan\"` and `drop_invariant = True`.\n",
    "- Set `handle = \"return_nan\"` and `drop_invariant = False`.\n",
    "\n",
    "Which settings do you think are better in production? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Race    Sex\n",
       "2   White   Male\n",
       "3   Black    NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Race      Sex\n",
       "4   Black   Female\n",
       "5   White   Female"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race_ White</th>\n",
       "      <th>Race_ Black</th>\n",
       "      <th>Sex_ Male</th>\n",
       "      <th>Sex_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Race_ White  Race_ Black  Sex_ Male  Sex_nan\n",
       "2            1            0          1        0\n",
       "3            0            1          0        1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehoter.fit(X_small_train)\n",
    "onehoter.transform(X_small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race_ White</th>\n",
       "      <th>Race_ Black</th>\n",
       "      <th>Sex_ Male</th>\n",
       "      <th>Sex_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Race_ White  Race_ Black  Sex_ Male  Sex_nan\n",
       "4            0            1          0        0\n",
       "5            1            0          0        0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehoter.transform(X_small_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run `OneHotEncoder` on the data. We create an instance of the class, which we call `onehoter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "handle = \"value\" # options are: 'error', 'return_nan', 'value', and 'indicator'\n",
    "onehoter =  ce.OneHotEncoder(return_df = True, \n",
    "                             cols = cat_vars, \n",
    "                             drop_invariant = False,\n",
    "                             use_cat_names = True, \n",
    "                             handle_missing = handle, \n",
    "                             handle_unknown = handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we appy `onehoter` it to the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehoter.fit(X_train)\n",
    "X_train_encoded = onehoter.transform(X_train)\n",
    "X_test_encoded = onehoter.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape = (30162, 14)\n",
      "X_train_encoded shape = (30162, 104)\n",
      "X_test shape = (15060, 14)\n",
      "X_test_encoded shape = (15060, 104)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape = {}\".format(X_train.shape))\n",
    "print(\"X_train_encoded shape = {}\".format(X_train_encoded.shape))\n",
    "\n",
    "print(\"X_test shape = {}\".format(X_test.shape))\n",
    "print(\"X_test_encoded shape = {}\".format(X_test_encoded.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be a good idea to ensure that the training and test sets have the same number of columns before proceeding to the next step. This is one way to ensure that we have consistency between the two. We can use `assert` to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train_encoded.shape[1] == X_test_encoded.shape[1], 'assertion failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to train models on the one-hot-encoded data. Let's start with a random forest model. Notice that the `RandomForestClassifier` class below has several hyper-parameters such as `n_estimators`, `max_features`, `max_depth` and `min_leaf_size`. The latter two were inherited from the decision tree. For reasons that will become apparent later, we store these hyper-parameters in a dictionary called `hypers` and then pass them to the classifier. When we have a dictionary whose keys match a fuction's argument names, there is a neat functionality in Python that allows us to pass the dictionary to the function using `**` followed by the name of the dictionary. This saves us from having to type the argument names twice: once in the dictionary and once when calling the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid red\"> </hr>\n",
    "\n",
    "## Training a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "hypers = {\"n_estimators\": 500, \"max_features\": \"sqrt\", \"max_depth\": 20, \"min_samples_leaf\": 10}\n",
    "clf_rf = RandomForestClassifier(random_state = 0, verbose = True, **hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   15.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, max_features='sqrt', min_samples_leaf=10,\n",
       "                       n_estimators=500, random_state=0, verbose=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.fit(X_train_encoded, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see a message about using a sequential backend, it's because a random forest is an algorithm that can easily run in parallel by just training many trees concurrently. Since we don't have a large data set we don't need to bother with that here, but it's useful to know about this in case we need to speed up the training job.\n",
    "\n",
    "\n",
    "> NOTE: in sklearn, each processor/thread needs duplicated data for itself. Here is a summary of reducing memory when parallelizing:\n",
    "\n",
    "https://mljar.com/blog/random-forest-memory/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One by product of tree-based models is that they provide us with a list showing the relative importance of each feature to the model. So even if we're not interested in the trained model the random forest returns, we can still use it for **feature selection**: namely train the random forest on the whole data to get the top $n$ most important features and later pass only those features to another algorithm we wish to use to train a model. Note that because we one-hot-encoded the data, a feature here is not just one of the categorical columns, but each category of each categorical column is its own feature. We can find the feature importance values in `clf_rf.feature_importances_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf_rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the feature importance values in a `DataFrame` and use `seaborn` to visualize the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_var_imp = pd.DataFrame({\"feature\": X_train_encoded.columns, \n",
    "                           \"importance\": clf_rf.feature_importances_})\n",
    "df_var_imp.sort_values(by = \"importance\", ascending = False, inplace = True)\n",
    "\n",
    "import seaborn as sns\n",
    "ax = sns.barplot(x = \"importance\", y = \"feature\", data = df_var_imp.head(10), color = \"lightblue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get predictions from the trained model, we simply call the `predict` method and pass it the data. To check if we're overfitting or not, we can get predictions for both the training and the test data. Once we have the predictions, we can call the `accuracy_score` function to get the accuracy on the training and test data, assuming that accuracy is a good metric to use here.\n",
    "\n",
    "We're already written the code there for you. But there's a problem with it. Your job is to run it and see if you can debug it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "Y_hat_train = clf_rf.predict(X_train_encoded)\n",
    "Y_hat_test = clf_rf.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     <=50K\n",
       "1     <=50K\n",
       "2     <=50K\n",
       "3     <=50K\n",
       "4     <=50K\n",
       "Name: Target, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     <=50K.\n",
       "1     <=50K.\n",
       "2      >50K.\n",
       "3      >50K.\n",
       "5     <=50K.\n",
       "Name: Target, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight discrepancy between the labels as they show up in the training data and the test data: the labels in the test data end with a period. So we need to remove the period when we evaluate the model. We do so using `.str.replace(\"\\\\.$\", \"\")` in the cell below, where `\"\\\\.$\"` is a regular expression that searches for a period at the end of a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 86.35%\n",
      "Test set accuracy: 85.76%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_train = accuracy_score(Y_train, Y_hat_train)\n",
    "\n",
    "end_of_line_period_regex = r'\\.$'\n",
    "\n",
    "acc_test = accuracy_score(Y_test.str.replace(end_of_line_period_regex, \"\"), Y_hat_test)\n",
    "\n",
    "print('Train set accuracy: {:.2f}%'.format(acc_train * 100))\n",
    "print('Test set accuracy: {:.2f}%'.format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be storing some important results in a table we call `results`. If this table doesn't exist (first time we run it) it will initialized by the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    results # checks if this object exists or not\n",
    "except NameError:\n",
    "    results = pd.DataFrame(columns = [\"algo\", \"acc_train\", \"acc_test\"]) # initiates it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every row of the table will store accuracy metrics for one training iteration given one set of hyper-parameters (also listed in the table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Changed to RandomForestClassifier\n",
      "\n",
      "-Hyperparameters:\n",
      "500\n",
      "sqrt\n",
      "20\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Create metrics:\n",
    "print(clf_rf.__class__)\n",
    "\n",
    "model_name = str(clf_rf.__class__).split('.')[-1].strip(\"\\\"\\'>\")\n",
    "\n",
    "print('Changed to {}'.format(model_name))\n",
    "\n",
    "\n",
    "\n",
    "results.loc[len(results), 0:3] = [model_name, acc_train, acc_test]\n",
    "\n",
    "print('\\n-Hyperparameters:')\n",
    "for hp in hypers.keys():\n",
    "    print(hypers[hp])\n",
    "    results.loc[len(results) - 1, hp] = hypers[hp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.863504</td>\n",
       "      <td>0.85757</td>\n",
       "      <td>500.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     algo acc_train acc_test  n_estimators max_features  \\\n",
       "0  RandomForestClassifier  0.863504  0.85757         500.0         sqrt   \n",
       "\n",
       "   max_depth  min_samples_leaf  \n",
       "0       20.0              10.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now go back up to where we trained the random forest classifier and change its hyper-parameters, retrain it, re-evaluate it, and finally store the results as a new row in the `results` table. This way we can compare our different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model:clf_rf1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model:clf_rf2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model:clf_rf3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "hypers = [{\"n_estimators\": 100, \"max_features\": \"sqrt\", \"max_depth\": 5, \"min_samples_leaf\": 10},\n",
    "          {\"n_estimators\": 100, \"max_features\": \"sqrt\", \"max_depth\": 7, \"min_samples_leaf\": 15},\n",
    "          {\"n_estimators\": 100, \"max_features\": \"sqrt\", \"max_depth\": 9, \"min_samples_leaf\": 20}]\n",
    "\n",
    "model_dict = {'clf_rf1': RandomForestClassifier(random_state = 0, verbose = True, **hypers[0]),\n",
    "              'clf_rf2': RandomForestClassifier(random_state = 0, verbose = True, **hypers[1]),\n",
    "              'clf_rf3': RandomForestClassifier(random_state = 0, verbose = True, **hypers[2])}\n",
    "\n",
    "\n",
    "for model_ix, (model_name, model_fun) in enumerate(model_dict.items()):\n",
    "    print('Training Model:{}'.format(model_name))\n",
    "    # Train model\n",
    "    model_fun.fit(X_train_encoded, Y_train)\n",
    "\n",
    "    # Get predictions\n",
    "    Y_hat_train = model_fun.predict(X_train_encoded)\n",
    "    Y_hat_test = model_fun.predict(X_test_encoded)\n",
    "\n",
    "    # Compute Accuracies\n",
    "    acc_train = accuracy_score(Y_train, Y_hat_train)\n",
    "    acc_test = accuracy_score(Y_test.str.replace(\"\\\\.$\", \"\"), Y_hat_test)\n",
    "\n",
    "    try:\n",
    "        results # checks if this object exists or not\n",
    "    except NameError:\n",
    "        results = pd.DataFrame(columns = [\"algo\", \"acc_train\", \"acc_test\"])\n",
    "\n",
    "    results.loc[len(results), 0:3] = [model_name, acc_train, acc_test]\n",
    "\n",
    "    for hp in hypers[model_ix].keys():\n",
    "        results.loc[len(results) - 1, hp] = hypers[model_ix][hp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we end up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.863504</td>\n",
       "      <td>0.85757</td>\n",
       "      <td>500.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clf_rf1</td>\n",
       "      <td>0.835754</td>\n",
       "      <td>0.832935</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clf_rf2</td>\n",
       "      <td>0.84381</td>\n",
       "      <td>0.841965</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clf_rf3</td>\n",
       "      <td>0.850209</td>\n",
       "      <td>0.847078</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     algo acc_train  acc_test  n_estimators max_features  \\\n",
       "0  RandomForestClassifier  0.863504   0.85757         500.0         sqrt   \n",
       "1                 clf_rf1  0.835754  0.832935         100.0         sqrt   \n",
       "2                 clf_rf2   0.84381  0.841965         100.0         sqrt   \n",
       "3                 clf_rf3  0.850209  0.847078         100.0         sqrt   \n",
       "\n",
       "   max_depth  min_samples_leaf  \n",
       "0       20.0              10.0  \n",
       "1        5.0              10.0  \n",
       "2        7.0              15.0  \n",
       "3        9.0              20.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid red\"> </hr>\n",
    "\n",
    "## Training a gradient boosted classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train a gradient boosted classifier. Shrinkage is controlled by `learning_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "hypers = {\"n_estimators\": 10, \"max_features\": \"sqrt\", \"max_depth\": 20, \"min_samples_leaf\": 10, \"learning_rate\": 0.5}\n",
    "clf_gb = GradientBoostingClassifier(loss = 'deviance', verbose = True, **hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One again we train the classifier by calling `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8050            0.77s\n",
      "         2           0.7006            0.68s\n",
      "         3           0.6301            0.61s\n",
      "         4           0.5860            0.53s\n",
      "         5           0.5530            0.45s\n",
      "         6           0.5301            0.35s\n",
      "         7           0.5095            0.26s\n",
      "         8           0.4921            0.17s\n",
      "         9           0.4751            0.09s\n",
      "        10           0.4665            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.5, max_depth=20, max_features='sqrt',\n",
       "                           min_samples_leaf=10, n_estimators=10, verbose=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gb.fit(X_train_encoded, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display the variable importance plot for a gradient boosted classifier as well. The results should not look very different from using random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_var_imp = pd.DataFrame({\"feature\": X_train_encoded.columns, \n",
    "                           \"importance\": clf_gb.feature_importances_})\n",
    "df_var_imp.sort_values(by = \"importance\", ascending = False, inplace = True)\n",
    "\n",
    "import seaborn as sns\n",
    "ax = sns.barplot(x = \"importance\", y = \"feature\", data = df_var_imp.head(10), color = \"lightblue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now score the training and test sets with the trained model from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_train = clf_gb.predict(X_train_encoded)\n",
    "Y_hat_test = clf_gb.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the accuracy scores in either case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 89.49%\n",
      "Test set accuracy: 85.72%\n"
     ]
    }
   ],
   "source": [
    "acc_train = accuracy_score(Y_train, Y_hat_train)\n",
    "acc_test = accuracy_score(Y_test.str.replace(\"\\\\.$\", \"\"), Y_hat_test)\n",
    "\n",
    "print('Train set accuracy: {:.2f}%'.format(acc_train * 100))\n",
    "print('Test set accuracy: {:.2f}%'.format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we store the results in the same `results` table as bofere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = str(clf_gb.__class__).split('.')[-1].strip(\"\\\"\\'>\")\n",
    "results.loc[len(results), 0:3] = [model_name, acc_train, acc_test]\n",
    "\n",
    "for hp in hypers.keys():\n",
    "    results.loc[len(results) - 1, hp] = hypers[hp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.863504</td>\n",
       "      <td>0.85757</td>\n",
       "      <td>500.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clf_rf1</td>\n",
       "      <td>0.835754</td>\n",
       "      <td>0.832935</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clf_rf2</td>\n",
       "      <td>0.84381</td>\n",
       "      <td>0.841965</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clf_rf3</td>\n",
       "      <td>0.850209</td>\n",
       "      <td>0.847078</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.894901</td>\n",
       "      <td>0.857238</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         algo acc_train  acc_test  n_estimators max_features  \\\n",
       "0      RandomForestClassifier  0.863504   0.85757         500.0         sqrt   \n",
       "1                     clf_rf1  0.835754  0.832935         100.0         sqrt   \n",
       "2                     clf_rf2   0.84381  0.841965         100.0         sqrt   \n",
       "3                     clf_rf3  0.850209  0.847078         100.0         sqrt   \n",
       "4  GradientBoostingClassifier  0.894901  0.857238          10.0         sqrt   \n",
       "\n",
       "   max_depth  min_samples_leaf  learning_rate  \n",
       "0       20.0              10.0            NaN  \n",
       "1        5.0              10.0            NaN  \n",
       "2        7.0              15.0            NaN  \n",
       "3        9.0              20.0            NaN  \n",
       "4       20.0              10.0            0.5  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid red\"> </hr>\n",
    "\n",
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to the two classifiers we trained above and change the hyper-parametrs and train at least 10 different random forest and 10 different gradient boosted classfiers. Make sure to store all the training runs in the `results` table. Once you have all the runs, find the best model you have and report its accuracy and state your choice of hyper-parametrs. We will compare this with everyone else in class to see who got the best model.\n",
    "\n",
    "Before you begin, recall that bagged learners like random forests reduce variance, so we want their **base-learner** to be more likely overfit (**high variance**). On the other hand, boosted learners like gradient boosted trees reduce bias, so we want their **base-learners** to be more likely to underfit (**high bias**). So your choice of hyper-parameters for the base-learners (decision trees) in each case should reflect this tendency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easy, we're already pasted the cells for you here. You will train 10 different **random forests**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model:clf_rf4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model:clf_rf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model:clf_rf6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model:clf_rf7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model:clf_rf8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    7.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model:clf_gb1\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0460            0.35s\n",
      "         2           0.9845            0.35s\n",
      "         3           0.9429            0.31s\n",
      "         4           0.9002            0.26s\n",
      "         5           0.8639            0.22s\n",
      "         6           0.8347            0.17s\n",
      "         7           0.8073            0.13s\n",
      "         8           0.7836            0.09s\n",
      "         9           0.7647            0.04s\n",
      "        10           0.7449            0.00s\n",
      "Training Model:clf_gb2\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0341            0.74s\n",
      "         2           0.9680            0.65s\n",
      "         3           0.9148            0.57s\n",
      "         4           0.8700            0.50s\n",
      "         5           0.8325            0.42s\n",
      "         6           0.8002            0.33s\n",
      "         7           0.7710            0.25s\n",
      "         8           0.7451            0.17s\n",
      "         9           0.7222            0.08s\n",
      "        10           0.7033            0.00s\n",
      "Training Model:clf_gb3\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0401            0.71s\n",
      "         2           0.9721            0.70s\n",
      "         3           0.9157            0.65s\n",
      "         4           0.8705            0.57s\n",
      "         5           0.8304            0.49s\n",
      "         6           0.7956            0.39s\n",
      "         7           0.7640            0.30s\n",
      "         8           0.7365            0.20s\n",
      "         9           0.7131            0.10s\n",
      "        10           0.6929            0.00s\n",
      "Training Model:clf_gb4\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8241            0.45s\n",
      "         2           0.7201            0.40s\n",
      "         3           0.6695            0.33s\n",
      "         4           0.6389            0.27s\n",
      "         5           0.6120            0.22s\n",
      "         6           0.5972            0.17s\n",
      "         7           0.5827            0.13s\n",
      "         8           0.5742            0.09s\n",
      "         9           0.5654            0.04s\n",
      "        10           0.5569            0.00s\n",
      "Training Model:clf_gb5\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7962            0.77s\n",
      "         2           0.6770            0.76s\n",
      "         3           0.6164            0.68s\n",
      "         4           0.5667            0.59s\n",
      "         5           0.5297            0.51s\n",
      "         6           0.5006            0.41s\n",
      "         7           0.4754            0.31s\n",
      "         8           0.4537            0.21s\n",
      "         9           0.4350            0.10s\n",
      "        10           0.4198            0.00s\n"
     ]
    }
   ],
   "source": [
    "hypers = [{\"n_estimators\": 300, \"max_features\": \"sqrt\", \"max_depth\": 5, \"min_samples_leaf\": 10},\n",
    "          {\"n_estimators\": 300, \"max_features\": \"sqrt\", \"max_depth\": 7, \"min_samples_leaf\": 15},\n",
    "          {\"n_estimators\": 300, \"max_features\": \"sqrt\", \"max_depth\": 9, \"min_samples_leaf\": 20},\n",
    "          {\"n_estimators\": 300, \"max_features\": \"sqrt\", \"max_depth\": 3, \"min_samples_leaf\": 20},\n",
    "          {\"n_estimators\": 300, \"max_features\": \"sqrt\", \"max_depth\": 11, \"min_samples_leaf\": 10},\n",
    "         {\"n_estimators\": 10, \"max_features\": \"sqrt\", \"max_depth\": 10, \"min_samples_leaf\": 10, \"learning_rate\": 0.1},\n",
    "         {\"n_estimators\": 10, \"max_features\": \"sqrt\", \"max_depth\": 20, \"min_samples_leaf\": 10, \"learning_rate\": 0.1},\n",
    "         {\"n_estimators\": 10, \"max_features\": \"sqrt\", \"max_depth\": 30, \"min_samples_leaf\": 10, \"learning_rate\": 0.1},\n",
    "         {\"n_estimators\": 10, \"max_features\": \"sqrt\", \"max_depth\": 10, \"min_samples_leaf\": 10, \"learning_rate\": 0.5},\n",
    "         {\"n_estimators\": 10, \"max_features\": \"sqrt\", \"max_depth\": 30, \"min_samples_leaf\": 10, \"learning_rate\": 0.5}]\n",
    "\n",
    "\n",
    "model_dict = {'clf_rf4': RandomForestClassifier(random_state = 0, verbose = True, **hypers[0]),\n",
    "              'clf_rf5': RandomForestClassifier(random_state = 0, verbose = True, **hypers[1]),\n",
    "              'clf_rf6': RandomForestClassifier(random_state = 0, verbose = True, **hypers[2]),\n",
    "              'clf_rf7': RandomForestClassifier(random_state = 0, verbose = True, **hypers[3]),\n",
    "              'clf_rf8': RandomForestClassifier(random_state = 0, verbose = True, **hypers[4]), \n",
    "              'clf_gb1': GradientBoostingClassifier(loss = 'deviance', verbose = True, **hypers[5]),\n",
    "             'clf_gb2': GradientBoostingClassifier(loss = 'deviance', verbose = True, **hypers[6]),\n",
    "             'clf_gb3': GradientBoostingClassifier(loss = 'deviance', verbose = True, **hypers[7]),\n",
    "             'clf_gb4': GradientBoostingClassifier(loss = 'deviance', verbose = True, **hypers[8]),\n",
    "             'clf_gb5': GradientBoostingClassifier(loss = 'deviance', verbose = True, **hypers[9])}\n",
    "\n",
    "\n",
    "for model_ix, (model_name, model_fun) in enumerate(model_dict.items()):\n",
    "    print('Training Model:{}'.format(model_name))\n",
    "    # Train model\n",
    "    model_fun.fit(X_train_encoded, Y_train)\n",
    "\n",
    "    # Get predictions\n",
    "    Y_hat_train = model_fun.predict(X_train_encoded)\n",
    "    Y_hat_test = model_fun.predict(X_test_encoded)\n",
    "\n",
    "    # Compute Accuracies\n",
    "    acc_train = accuracy_score(Y_train, Y_hat_train)\n",
    "    acc_test = accuracy_score(Y_test.str.replace(\"\\\\.$\", \"\"), Y_hat_test)\n",
    "\n",
    "    try:\n",
    "        results # checks if this object exists or not\n",
    "    except NameError:\n",
    "        results = pd.DataFrame(columns = [\"algo\", \"acc_train\", \"acc_test\"]) # initiates it\n",
    "\n",
    "    results.loc[len(results), 0:3] = [model_name, acc_train, acc_test]\n",
    "\n",
    "    for hp in hypers[model_ix].keys():\n",
    "        results.loc[len(results) - 1, hp] = hypers[model_ix][hp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.863504</td>\n",
       "      <td>0.85757</td>\n",
       "      <td>500.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clf_rf1</td>\n",
       "      <td>0.835754</td>\n",
       "      <td>0.832935</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clf_rf2</td>\n",
       "      <td>0.84381</td>\n",
       "      <td>0.841965</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clf_rf3</td>\n",
       "      <td>0.850209</td>\n",
       "      <td>0.847078</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.894901</td>\n",
       "      <td>0.857238</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clf_rf4</td>\n",
       "      <td>0.835588</td>\n",
       "      <td>0.832072</td>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clf_rf5</td>\n",
       "      <td>0.843744</td>\n",
       "      <td>0.841899</td>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clf_rf6</td>\n",
       "      <td>0.850507</td>\n",
       "      <td>0.847078</td>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clf_rf7</td>\n",
       "      <td>0.793714</td>\n",
       "      <td>0.795418</td>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>clf_rf8</td>\n",
       "      <td>0.856574</td>\n",
       "      <td>0.852191</td>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>clf_gb1</td>\n",
       "      <td>0.843213</td>\n",
       "      <td>0.83911</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>clf_gb2</td>\n",
       "      <td>0.860255</td>\n",
       "      <td>0.848938</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>clf_gb3</td>\n",
       "      <td>0.861614</td>\n",
       "      <td>0.846614</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>clf_gb4</td>\n",
       "      <td>0.873483</td>\n",
       "      <td>0.854648</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>clf_gb5</td>\n",
       "      <td>0.908726</td>\n",
       "      <td>0.855113</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          algo acc_train  acc_test  n_estimators max_features  \\\n",
       "0       RandomForestClassifier  0.863504   0.85757         500.0         sqrt   \n",
       "1                      clf_rf1  0.835754  0.832935         100.0         sqrt   \n",
       "2                      clf_rf2   0.84381  0.841965         100.0         sqrt   \n",
       "3                      clf_rf3  0.850209  0.847078         100.0         sqrt   \n",
       "4   GradientBoostingClassifier  0.894901  0.857238          10.0         sqrt   \n",
       "5                      clf_rf4  0.835588  0.832072         300.0         sqrt   \n",
       "6                      clf_rf5  0.843744  0.841899         300.0         sqrt   \n",
       "7                      clf_rf6  0.850507  0.847078         300.0         sqrt   \n",
       "8                      clf_rf7  0.793714  0.795418         300.0         sqrt   \n",
       "9                      clf_rf8  0.856574  0.852191         300.0         sqrt   \n",
       "10                     clf_gb1  0.843213   0.83911          10.0         sqrt   \n",
       "11                     clf_gb2  0.860255  0.848938          10.0         sqrt   \n",
       "12                     clf_gb3  0.861614  0.846614          10.0         sqrt   \n",
       "13                     clf_gb4  0.873483  0.854648          10.0         sqrt   \n",
       "14                     clf_gb5  0.908726  0.855113          10.0         sqrt   \n",
       "\n",
       "    max_depth  min_samples_leaf  learning_rate  \n",
       "0        20.0              10.0            NaN  \n",
       "1         5.0              10.0            NaN  \n",
       "2         7.0              15.0            NaN  \n",
       "3         9.0              20.0            NaN  \n",
       "4        20.0              10.0            0.5  \n",
       "5         5.0              10.0            NaN  \n",
       "6         7.0              15.0            NaN  \n",
       "7         9.0              20.0            NaN  \n",
       "8         3.0              20.0            NaN  \n",
       "9        11.0              10.0            NaN  \n",
       "10       10.0              10.0            0.1  \n",
       "11       20.0              10.0            0.1  \n",
       "12       30.0              10.0            0.1  \n",
       "13       10.0              10.0            0.5  \n",
       "14       30.0              10.0            0.5  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid red\"> </hr>\n",
    "\n",
    "## Early Stopping w/ GBM\n",
    "\n",
    "It is easy to overfit with `GradientBoostingClassifier`, because as we saw boosting tries to model the residual error, and iteration after iteration the error we are left with contains less and less signal and more and more noise. To that end, it is useful to implement what's called **early stopping**:\n",
    "\n",
    "- we set aside a validation data\n",
    "- as we train the base classifier at each iteration, we predict on the validation data and compute the error\n",
    "- if validation error doesn't improve **after a certain number of iterations by at least a certain percentage** (called the **tolerance**), we stop the trainig\n",
    "\n",
    "In `GradientBoostingClassifier` early stopping can be implemented using the `validation_fraction`, `n_iter_no_change` and `tol` arguments. You can read [the documentation](https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_early_stopping.html) for more details on this.\n",
    "\n",
    "Run one more run of `GradientBoostingClassifier` and this time implement early stopping. After training, you can check the number of iterations that were run by running `model.n_estimators_`. Normally this is just the number of iterations you chose to run, but if early stopping is implemented then it can be a smaller number.\n",
    "\n",
    "When you're done with your runs, you can check all the results by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8052            6.38s\n",
      "         2           0.6859            6.61s\n",
      "         3           0.6197            6.95s\n",
      "         4           0.5771            7.03s\n",
      "         5           0.5420            7.03s\n",
      "         6           0.5172            7.02s\n",
      "         7           0.4948            7.07s\n",
      "         8           0.4791            6.80s\n",
      "         9           0.4647            6.70s\n",
      "Train set accuracy: 88.79%\n",
      "Test set accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "hypers_w_early_stop = {\"n_estimators\": 100, \"max_features\": \"sqrt\", \"max_depth\": 20, \"min_samples_leaf\": 10,\n",
    "                       \"learning_rate\": 0.5, \"validation_fraction\": 0.20, \"n_iter_no_change\": 3, \"tol\": 0.01}\n",
    "\n",
    "clf_gb_stop = GradientBoostingClassifier(loss = 'deviance', verbose = True, **hypers_w_early_stop)\n",
    "\n",
    "clf_gb_stop.fit(X_train_encoded, Y_train)\n",
    "\n",
    "# Accuracies\n",
    "Y_hat_train = clf_gb_stop.predict(X_train_encoded)\n",
    "Y_hat_test = clf_gb_stop.predict(X_test_encoded)\n",
    "\n",
    "acc_train = accuracy_score(Y_train, Y_hat_train)\n",
    "acc_test = accuracy_score(Y_test.str.replace(\"\\\\.$\", \"\"), Y_hat_test)\n",
    "\n",
    "print('Train set accuracy: {:.2f}%'.format(acc_train * 100))\n",
    "print('Test set accuracy: {:.2f}%'.format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add this to the result frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = str(clf_gb_stop.__class__).split('.')[-1].strip(\"\\\"\\'>\")\n",
    "results.loc[len(results), 0:3] = [model_name, acc_train, acc_test]\n",
    "\n",
    "for hp in hypers_w_early_stop.keys():\n",
    "    results.loc[len(results) - 1, hp] = hypers_w_early_stop[hp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>validation_fraction</th>\n",
       "      <th>n_iter_no_change</th>\n",
       "      <th>tol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.863504</td>\n",
       "      <td>0.85757</td>\n",
       "      <td>500.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clf_rf1</td>\n",
       "      <td>0.835754</td>\n",
       "      <td>0.832935</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clf_rf2</td>\n",
       "      <td>0.84381</td>\n",
       "      <td>0.841965</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clf_rf3</td>\n",
       "      <td>0.850209</td>\n",
       "      <td>0.847078</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.894901</td>\n",
       "      <td>0.857238</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clf_rf4</td>\n",
       "      <td>0.835588</td>\n",
       "      <td>0.832072</td>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clf_rf5</td>\n",
       "      <td>0.843744</td>\n",
       "      <td>0.841899</td>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clf_rf6</td>\n",
       "      <td>0.850507</td>\n",
       "      <td>0.847078</td>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clf_rf7</td>\n",
       "      <td>0.793714</td>\n",
       "      <td>0.795418</td>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>clf_rf8</td>\n",
       "      <td>0.856574</td>\n",
       "      <td>0.852191</td>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>clf_gb1</td>\n",
       "      <td>0.843213</td>\n",
       "      <td>0.83911</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>clf_gb2</td>\n",
       "      <td>0.860255</td>\n",
       "      <td>0.848938</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>clf_gb3</td>\n",
       "      <td>0.861614</td>\n",
       "      <td>0.846614</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>clf_gb4</td>\n",
       "      <td>0.873483</td>\n",
       "      <td>0.854648</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>clf_gb5</td>\n",
       "      <td>0.908726</td>\n",
       "      <td>0.855113</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.908726</td>\n",
       "      <td>0.855113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.887905</td>\n",
       "      <td>0.857105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.887905</td>\n",
       "      <td>0.857105</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          algo acc_train  acc_test  n_estimators max_features  \\\n",
       "0       RandomForestClassifier  0.863504   0.85757         500.0         sqrt   \n",
       "1                      clf_rf1  0.835754  0.832935         100.0         sqrt   \n",
       "2                      clf_rf2   0.84381  0.841965         100.0         sqrt   \n",
       "3                      clf_rf3  0.850209  0.847078         100.0         sqrt   \n",
       "4   GradientBoostingClassifier  0.894901  0.857238          10.0         sqrt   \n",
       "5                      clf_rf4  0.835588  0.832072         300.0         sqrt   \n",
       "6                      clf_rf5  0.843744  0.841899         300.0         sqrt   \n",
       "7                      clf_rf6  0.850507  0.847078         300.0         sqrt   \n",
       "8                      clf_rf7  0.793714  0.795418         300.0         sqrt   \n",
       "9                      clf_rf8  0.856574  0.852191         300.0         sqrt   \n",
       "10                     clf_gb1  0.843213   0.83911          10.0         sqrt   \n",
       "11                     clf_gb2  0.860255  0.848938          10.0         sqrt   \n",
       "12                     clf_gb3  0.861614  0.846614          10.0         sqrt   \n",
       "13                     clf_gb4  0.873483  0.854648          10.0         sqrt   \n",
       "14                     clf_gb5  0.908726  0.855113          10.0         sqrt   \n",
       "15  GradientBoostingClassifier  0.908726  0.855113           NaN          NaN   \n",
       "16  GradientBoostingClassifier  0.887905  0.857105           NaN          NaN   \n",
       "17  GradientBoostingClassifier  0.887905  0.857105         100.0         sqrt   \n",
       "\n",
       "    max_depth  min_samples_leaf  learning_rate  validation_fraction  \\\n",
       "0        20.0              10.0            NaN                  NaN   \n",
       "1         5.0              10.0            NaN                  NaN   \n",
       "2         7.0              15.0            NaN                  NaN   \n",
       "3         9.0              20.0            NaN                  NaN   \n",
       "4        20.0              10.0            0.5                  NaN   \n",
       "5         5.0              10.0            NaN                  NaN   \n",
       "6         7.0              15.0            NaN                  NaN   \n",
       "7         9.0              20.0            NaN                  NaN   \n",
       "8         3.0              20.0            NaN                  NaN   \n",
       "9        11.0              10.0            NaN                  NaN   \n",
       "10       10.0              10.0            0.1                  NaN   \n",
       "11       20.0              10.0            0.1                  NaN   \n",
       "12       30.0              10.0            0.1                  NaN   \n",
       "13       10.0              10.0            0.5                  NaN   \n",
       "14       30.0              10.0            0.5                  NaN   \n",
       "15        NaN               NaN            NaN                  NaN   \n",
       "16        NaN               NaN            NaN                  NaN   \n",
       "17       20.0              10.0            0.5                  0.2   \n",
       "\n",
       "    n_iter_no_change   tol  \n",
       "0                NaN   NaN  \n",
       "1                NaN   NaN  \n",
       "2                NaN   NaN  \n",
       "3                NaN   NaN  \n",
       "4                NaN   NaN  \n",
       "5                NaN   NaN  \n",
       "6                NaN   NaN  \n",
       "7                NaN   NaN  \n",
       "8                NaN   NaN  \n",
       "9                NaN   NaN  \n",
       "10               NaN   NaN  \n",
       "11               NaN   NaN  \n",
       "12               NaN   NaN  \n",
       "13               NaN   NaN  \n",
       "14               NaN   NaN  \n",
       "15               NaN   NaN  \n",
       "16               NaN   NaN  \n",
       "17               3.0  0.01  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you check the classifier's documentation and understand what `n_estimators`, `max_features`, `max_depth`, and `min_leaf_size` represent. Then, answer the following question:\n",
    "\n",
    "- What seems to be the effect of changing each of these hyper-parameters on the accuracy of the training and test data?\n",
    "- Does this match your intuition about how these hyper-parameters work?\n",
    "- Are there any hyper-parameters that seem promising and worth trying to tune?\n",
    "\n",
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning can be a very time-consuming and difficult task. In a future lecture, we will see how we can use a Python library to automatically specify different hyper-parameter values ahead of time and train different models. This will save us from having to manually re-run external scripts or collect results, but for now this will suffice and it's also a chance to show-case some more advanced Python and Jupyter functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid red\"> </hr>\n",
    "\n",
    "## Visually Overfitting\n",
    "\n",
    "Let's compare how overfitting behaves between GBM and Random Forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models for n=2. Please wait.\n",
      "Fitting models for n=3. Please wait.\n",
      "Fitting models for n=4. Please wait.\n",
      "Fitting models for n=5. Please wait.\n",
      "Fitting models for n=10. Please wait.\n",
      "Fitting models for n=15. Please wait.\n",
      "Fitting models for n=20. Please wait.\n",
      "Fitting models for n=25. Please wait.\n",
      "Fitting models for n=30. Please wait.\n",
      "Fitting models for n=40. Please wait.\n",
      "Fitting models for n=50. Please wait.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n_estimators = [2, 3, 4, 5, 10, 15, 20, 25, 30, 40, 50]\n",
    "\n",
    "rf_train_acc = []\n",
    "rf_test_acc = []\n",
    "gbm_train_acc = []\n",
    "gbm_test_acc = []\n",
    "gbms_train_acc = []\n",
    "gbms_test_acc = []\n",
    "\n",
    "for n in n_estimators:\n",
    "    print('Fitting models for n={}. Please wait.'.format(n))\n",
    "    rf_hypers = {\"n_estimators\": n, \"max_features\": \"sqrt\", \"max_depth\": 10, \"min_samples_leaf\": 10}\n",
    "    gbm_hypers = {\"n_estimators\": n, \"max_features\": \"sqrt\", \"max_depth\": 10, \"min_samples_leaf\": 10,\n",
    "                  \"learning_rate\": 0.5}\n",
    "    gbm_stop_hypers = {\"n_estimators\": n, \"max_features\": \"sqrt\", \"max_depth\": 10, \"min_samples_leaf\": 10,\n",
    "                       \"learning_rate\": 0.5, \"validation_fraction\": 0.20, \"n_iter_no_change\": 3, \"tol\": 0.01}\n",
    "    \n",
    "    # Setup Models\n",
    "    rf_model = RandomForestClassifier(random_state = 0, verbose = False, **rf_hypers)\n",
    "    gbm_model = GradientBoostingClassifier(loss = 'deviance', verbose = False, **gbm_hypers)\n",
    "    gbm_stop_model = GradientBoostingClassifier(loss = 'deviance', verbose = False, **gbm_stop_hypers)\n",
    "    \n",
    "    # Fit models\n",
    "    rf_model.fit(X_train_encoded, Y_train)\n",
    "    gbm_model.fit(X_train_encoded, Y_train)\n",
    "    gbm_stop_model.fit(X_train_encoded, Y_train)\n",
    "    \n",
    "    # Get accuracies\n",
    "    Y_hat_train_rf = rf_model.predict(X_train_encoded)\n",
    "    Y_hat_test_rf = rf_model.predict(X_test_encoded)\n",
    "    Y_hat_train_gbm = gbm_model.predict(X_train_encoded)\n",
    "    Y_hat_test_gbm = gbm_model.predict(X_test_encoded)\n",
    "    Y_hat_train_gbms = gbm_stop_model.predict(X_train_encoded)\n",
    "    Y_hat_test_gbms = gbm_stop_model.predict(X_test_encoded)\n",
    "\n",
    "    acc_train_rf = accuracy_score(Y_train, Y_hat_train_rf)\n",
    "    acc_test_rf = accuracy_score(Y_test.str.replace(\"\\\\.$\", \"\"), Y_hat_test_rf)\n",
    "    acc_train_gbm = accuracy_score(Y_train, Y_hat_train_gbm)\n",
    "    acc_test_gbm = accuracy_score(Y_test.str.replace(\"\\\\.$\", \"\"), Y_hat_test_gbm)\n",
    "    acc_train_gbms = accuracy_score(Y_train, Y_hat_train_gbms)\n",
    "    acc_test_gbms = accuracy_score(Y_test.str.replace(\"\\\\.$\", \"\"), Y_hat_test_gbms)\n",
    "    \n",
    "    # Save outputs\n",
    "    rf_train_acc.append(acc_train_rf)\n",
    "    rf_test_acc.append(acc_test_rf)\n",
    "    gbm_train_acc.append(acc_train_gbm)\n",
    "    gbm_test_acc.append(acc_test_gbm)\n",
    "    gbms_train_acc.append(acc_train_gbms)\n",
    "    gbms_test_acc.append(acc_test_gbms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1252e1730>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot outputs\n",
    "plt.plot(n_estimators, rf_train_acc, label='RF Train')\n",
    "plt.plot(n_estimators, rf_test_acc, label='RF Test')\n",
    "plt.plot(n_estimators, gbm_train_acc, label='GBM Train')\n",
    "plt.plot(n_estimators, gbm_test_acc, label='GBM Test')\n",
    "plt.plot(n_estimators, gbms_train_acc, label='GBM-s Train')\n",
    "plt.plot(n_estimators, gbms_test_acc, label='GBM-s Test')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid red\"> </hr>\n",
    "\n",
    "## Training a non-tree-based ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finish this notebook by providing an example of a non-tree-based classifier. Tree-based classifiers are so common that they have their own functions in `sklearn`, but if we want we can choose any base-learners and pass it to the `BaggingClassifier` or any of the other ensemble learners in `sklearn.ensemble`. In the following example, we use `KNeighborsClassifier` as the base learner and train a bagged classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(), max_features=0.5,\n",
       "                  max_samples=0.5)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "bag_cls = BaggingClassifier(KNeighborsClassifier(), max_samples = 0.5, max_features = 0.5)\n",
    "bag_cls.fit(X_train_encoded, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can let the classifier predict on the training and test data.\n",
    "\n",
    "While it's computing, read over the documentation here:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May take a minute to compute\n",
    "Y_hat_train = bag_cls.predict(X_train_encoded)\n",
    "Y_hat_test = bag_cls.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And obtain just as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.865 and on test data = 0.833\n"
     ]
    }
   ],
   "source": [
    "acc_train = accuracy_score(Y_train, Y_hat_train)\n",
    "acc_test = accuracy_score(Y_test.str.replace(\"\\\\.$\", \"\"), Y_hat_test)\n",
    "\n",
    "print(\"Accuracy on training data = {:.03f} and on test data = {:.03f}\".format(acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So ensemble classifiers are a great method to improve accuracy if we're willing to pay the computational cost. Another downside as we saw in this notebook is that we add new hyper-parameters on top of the ones we inherit from the base learner and hyper-parameter tuning becomes a daunting task. In fact, one of the short-comings in this notebook is that we did our hyper-parameter tuning on the **test data** when we should have used a **validation data** instead. If we try a few different runs we can get away with this, but if we get serious about hyper-parameter tuning then as we learned the right way to do it is to evaluate the hyper-parameters on the **validation data** (or to use cross-validation) and leave the **test data** to evaluate the accuracy of the **final model** at the end."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
